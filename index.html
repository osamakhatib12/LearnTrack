
<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Osama Learning Report</title>
<link href="manifest.webmanifest" rel="manifest"/>
<style>
    body {
      background-color: #1a1a1a;
      color: #d4d4d8;
      font-family: 'Segoe UI', sans-serif;
      padding: 2rem;
      max-width: 900px;
      margin: auto;
      line-height: 1.7;
    }
    h1 {
      color: #60a5fa;
      font-size: 2rem;
      border-bottom: 1px solid #374151;
      padding-bottom: 0.3rem;
    }
    h2 {
      color: #facc15;
      font-size: 1.6rem;
      margin-top: 2rem;
    }
    h3 {
      color: #4ade80;
      font-size: 1.3rem;
      margin-top: 1.2rem;
    }
    p {
      color: #e4e4e7;
      margin-bottom: 1rem;
    }
    code {
      background-color: #2e2e30;
      color: #93c5fd;
      padding: 2px 6px;
      border-radius: 4px;
      font-family: monospace;
    }
    a {
      color: #38bdf8;
      text-decoration: underline;
    }
    a:hover {
      color: #7dd3fc;
    }
    ul {
      padding-left: 1.5rem;
    }
    li {
      margin-bottom: 0.4rem;
    }
  </style>
</head>
<body>
<h1>ğŸ§  Osama Al-Khatib â€“ Learning Progress Report</h1>
<h2>ğŸ‘¨â€ğŸ’» Overview</h2>
<p>This document summarizes my learning journey in programming, web scraping, backend development with Django, and an introduction to deep learning and cybersecurity. It reflects what I have already learned, what Iâ€™m currently focusing on, and my future learning plans and goals.</p>
<hr/>
<h2>âœ… What I've Learned So Far</h2>
<h3>ğŸ”¹ Python Programming</h3>
<ul>
<li>Mastered core Python: variables, loops, functions, conditionals, file handling.</li>
<li>Used Python to write scripts for data extraction, JSON handling, and more.</li>
</ul>
<h3>ğŸ”¹ Web Scraping</h3>
<ul>
<li>Learned multiple scraping methods:
<ul>
<li><code>requests</code> + <code>BeautifulSoup</code></li>
<li><code>requests-html</code> for rendering JS-based pages</li>
<li><code>Selenium</code> for dynamic page interaction and scrolling</li>
</ul></li>
<li>Successfully scraped:
<ul>
<li><strong>OpenSooq</strong> real estate listings with phone numbers</li>
<li><strong>OLX</strong> &amp; <strong>Dubizzle</strong> using DevTools and network requests</li>
<li><strong>Reddit</strong> posts and comments using full automation with Selenium</li>
</ul></li>
</ul>
<hr/>
<h2>ğŸ“˜ What Iâ€™m Currently Learning</h2>
<h3>ğŸ”¹ Django (Backend Web Development)</h3>
<ul>
<li>Project setup, virtual environments</li>
<li>Models, Views, Templates (MVT)</li>
<li>URL routing, forms, admin panel</li>
<li>Preparing to build full-stack apps</li>
</ul>
<h3>ğŸ”¹ Deep Learning (Intro)</h3>
<ul>
<li>Basics of neural networks</li>
<li>Watching Arabic tutorials on deep learning</li>
<li>Understanding how models learn from data (classification, image, and text processing)</li>
</ul>
<hr/>
<h2>ğŸ”® Future Plans and Goals</h2>
<h3>ğŸ”¸ Django</h3>
<ul>
<li>Learn advanced features (sessions, permissions, user auth)</li>
<li>Build and deploy real-world web apps (e.g., dashboards, blog, API-based apps)</li>
</ul>
<h3>ğŸ”¸ Deep Learning</h3>
<ul>
<li>Study CNNs, RNNs, NLP models using Keras and TensorFlow</li>
<li>Build smart models for image recognition or sentiment analysis</li>
<li>Integrate DL models into Django apps</li>
</ul>
<h3>ğŸ”¸ Cyber Security</h3>
<ul>
<li>Apply my knowledge from the Cyber Shield Academy:
<ul>
<li>Network analysis, forensics, SOC monitoring, threat hunting</li>
<li>Ethical hacking and Python-based pentesting tools</li>
</ul></li>
<li>Build secure apps by implementing proper authentication, logging, encryption, and protection from web attacks (XSS, SQLi, CSRF)</li>
<li>Explore AI-based cybersecurity solutions in the future</li>
</ul>
<hr/>
<h2>ğŸ“š Key Learning Resources</h2>
<h3>Django</h3>
<ul>
<li><a href="https://www.youtube.com/playlist?list=PLp2eAGIFKMEVnAAJWhGzLc1Nn-tFP1UHP">Django Arabic Course (YouTube)</a></li>
<li><a href="https://docs.djangoproject.com/en/stable/">Django Documentation</a></li>
</ul>
<h3>Deep Learning</h3>
<ul>
<li><a href="https://www.udemy.com/course/intro-to-deep-learning-arabic/">Intro to Deep Learning â€“ Arabic Course</a></li>
<li><a href="https://www.coursera.org/specializations/deep-learning">Deep Learning Specialization by Andrew Ng</a></li>
</ul>
<h3>Cyber Security</h3>
<ul>
<li>Cyber Shield Academy (JODDB)</li>
<li>SMT Security Training â€“ CSA, EHA, DFIRA, SOC, Threat Hunter</li>
<li><a href="https://tryhackme.com">TryHackMe</a>, <a href="https://www.hackthebox.com/">Hack The Box</a> â€“ for hands-on labs</li>
</ul>
<hr/>
<h2>ğŸ Final Thoughts</h2>
<h2>This roadmap is just the beginning of a long-term journey in tech, combining backend development, automation, AI, and security. I aim to build real-world projects, contribute to open source, and grow into a cybersecurity-aware developer with AI capabilities.</h2>
<h1>ğŸ“„ Reddit Web Scraping Project â€“ Technical Progress Report</h1>
<p><strong>Project Owner</strong>: Osama<br/>
<strong>Start Date</strong>: May 2025<br/>
<strong>Goal</strong>: Build a full-featured Reddit scraping system using Selenium, and evolve it into a professional portfolio project (for GitHub, LinkedIn, CV). Future integration with Django is planned.</p>
<h2>ğŸ¯ Project Motivation</h2>
<p>This project is more than a learning experience. It's a structured and scalable web scraping system built around Reddit. The motivation includes:
- Real-world challenge: Reddit has dynamic content, authentication, rate-limiting, nested data.
- Rich data variety: Posts, comments, replies, media, timestamps, etc.
- Evolving into a complete data pipeline with Django.</p>
<h2>âœ… Goals (Phase 1 - Web Scraping with Selenium)</h2>
<h3>Core Technical Objectives:</h3>
<ul>
<li>Use Selenium with ChromeDriver</li>
<li>Implement auto-scroll to load all post/comment content</li>
<li>Extract post-level data:
<ul>
<li>Username</li>
<li>Post title</li>
<li>Full post description (text + media + links)</li>
<li>Votes and comments count</li>
<li>Human-readable timestamps</li>
</ul></li>
<li>Extract all top-level comments:
<ul>
<li>Username</li>
<li>Full comment content (multi-type)</li>
<li>Time</li>
<li>Votes</li>
</ul></li>
<li>Extract replies (nested structure):
<ul>
<li>Track depth using <code>depth</code> attribute</li>
<li>Track identity using <code>comment-id</code> and <code>parent-id</code></li>
<li>Detect whether a comment has replies using <code>div[slot="next-reply"]</code></li>
<li>Detect hidden replies via "more replies" button</li>
</ul></li>
<li>Save post URLs to JSON file</li>
<li>Save detailed post + comments + replies to structured JSON file</li>
<li>Save progress file (for resume after crash / stopping)</li>
</ul>
<h3>ğŸ”§ Challenges Encountered &amp; Solved:</h3>
<ul>
<li>Post description not showing consistently -&gt; Solved by dynamic parsing of <code>div[id*=post-rtjson-content]</code></li>
<li>Comments missing or repeated -&gt; Solved by correct use of <code>.find_element</code> vs <code>.find_elements</code> + scrolling fixes</li>
<li>Usernames showing <code>None</code> -&gt; Fixed by using <code>get_attribute("author")</code></li>
<li>Votes/text not showing correctly -&gt; Fixed by correct XPath + wait conditions</li>
<li>Depth/Hierarchy confusion -&gt; Solved with comment-id/parent-id based tree tracking</li>
</ul>
<h2>ğŸ“ Project Files Structure</h2>
<ul>
<li><code>Extract_Comments_And_Replies.py</code> -&gt; main scraping logic</li>
<li><code>Functions_For_Scraping.py</code> -&gt; helper: <code>slow_scroll()</code></li>
<li><code>CommentsWithReplies.json</code> -&gt; Final structured output</li>
<li><code>postLinks.json</code> -&gt; URLs of posts collected for loop-based extraction</li>
</ul>
<h2>ğŸ”œ Next Steps (Upcoming Additions)</h2>
<ul>
<li>Handle "More replies" button dynamically</li>
<li>Support full recursion of replies (multi-depth nesting)</li>
<li>Build a reply tree using comment-id and parent-id mapping</li>
<li>Save replies inside <code>replies</code> array of each parent comment</li>
</ul>
<h2>ğŸ”„ Phase 2: Django Integration (Initial Planning)</h2>
<ul>
<li>Learn Django basics in parallel</li>
<li>Store Reddit post data in Django models</li>
<li>Build a dashboard to explore scraped content</li>
<li>Enable search, filter, and download from Django UI</li>
<li>Secure API endpoints for the dataset</li>
</ul>
<hr/>
<p><em>Report Update Frequency</em>: This document will be updated daily with new progress, challenges, and design decisions.<br/>
<em>Next update</em>: May 21, 2025<br/>
<em>Prepared by</em>: ChatGPT - Technical Assistant to Osama</p>
<h1>âœ… Updates Added (May 26â€“27)</h1>
<h3>âœ… May 26â€“27 Reddit Comment Extraction Enhancements</h3>
<ol>
<li><p>ğŸ§  Improved detection of hidden and collapsed comments:</p>
<ul>
<li>Recognized that some comments on Reddit remain hidden inside <code>&lt;details&gt;</code> tags or require scrolling/clicking to appear.</li>
<li>Adjusted logic to check for <code>shreddit-comment</code> components with <code>.collapsed</code> class, and detect when they change state to <code>open</code>.</li>
</ul></li>
<li><p>ğŸ” Nested reply handling and comment depth:</p>
<ul>
<li>Structured comments using unique comment IDs and parent-child relationships.</li>
<li>Added logic to expand replies using buttons found inside <code>&lt;slot name="next-reply"&gt;</code> or shadow DOM.</li>
<li>Ensured that even deeply nested replies (beyond level 3) are detected and stored correctly.</li>
</ul></li>
<li><p>ğŸ”„ Scroll-based full tree loading:</p>
<ul>
<li>Triggered scrolling to load all top-level comments and check for <code>load more comments</code> buttons.</li>
<li>Supported handling of "more replies" dynamically loaded after expanding collapsed sections.</li>
</ul></li>
<li><p>âœ… All improvements are now saved to structured JSON to maintain depth and reply order.</p></li>
</ol>
<h1>âœ… Updates Added (May 28â€“29)</h1>
<h2>ğŸ”„ Project Updates â€“ May 28â€“29, 2025</h2>
<h3>ğŸ“… 5/28 â€“ Dealing with Hidden Replies &amp; External Permalinks</h3>
<ul>
<li>Implemented detection logic for deep-level replies (depth=3) that have hidden "more replies" links pointing to separate permalink pages.</li>
<li>Created a dedicated script <code>extract_more_reply_links.py</code> to:
<ul>
<li>Scroll and click all "show more replies" buttons dynamically using <code>smart_scroll_and_click()</code>.</li>
<li>Detect comments with <code>depth=3</code> and extract their <code>&lt;a slot="more-comments-permalink"&gt;</code> URLs.</li>
<li>Avoid duplicates by checking <code>comment-id</code> against previously saved comments.</li>
<li>Save all collected links to <code>external_links.json</code>.</li>
</ul></li>
<li>Verified behavior with DevTools and screenshots to confirm the structure.</li>
</ul>
<h3>ğŸ› ï¸ Improvements on Smart Scrolling Logic</h3>
<ul>
<li>Enhanced <code>smart_scroll_and_click()</code> to scroll dynamically and click on reply buttons reliably.</li>
</ul>
<hr/>
<h3>ğŸ“… 5/29 â€“ Merging Replies from External Pages</h3>
<ul>
<li>Built the script <code>merge_external_replies.py</code> to:
<ul>
<li>Load collected external reply links.</li>
<li>Open each permalink page and run <code>extract_more_comments_and_replies_from_next_page()</code>.</li>
<li>Avoid duplication by:
<ul>
<li>Using a recursive <code>comment_id_exists()</code> function to deeply scan all comment trees.</li>
<li>Skipping new top-level comments that were previously replies (false top-level depth=0).</li>
</ul></li>
<li>Correctly insert nested replies using the recursive <code>insert_comment_in_tree()</code> function.</li>
<li>Save merged output to <code>Updated_CommentsWithReplies.json</code>.</li>
</ul></li>
</ul>
<h3>ğŸ› Bug Fixes &amp; Validations</h3>
<ul>
<li>Fixed an issue where some comment IDs were getting re-inserted as new top-level comments despite existing in reply trees.</li>
<li>Confirmed proper merging of deeply nested replies by manually comparing JSON structure and UI.</li>
</ul>
<h3>ğŸ” Manual Verifications</h3>
<ul>
<li>Used screenshots + comment tracing to validate:
<ul>
<li>Reply hierarchy (parent-id, depth, content).</li>
<li>Correct merge locations in the final output file.</li>
<li>No duplication after final patch.</li>
</ul></li>
</ul>
<hr/>
<h2>ğŸ“š Recommended Learning Resources (Arabic) (Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©)</h2>
<h3>ğŸŸ¢ Django:</h3>
<ul>
<li><p><strong>ÙƒÙˆØ±Ø³ Django Ø§Ù„ÙƒØ§Ù…Ù„ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ</strong>: Ø³Ù„Ø³Ù„Ø© Ø´Ø§Ù…Ù„Ø© Ù„ØªØ¹Ù„Ù… Django Ù…Ù† Ø§Ù„ØµÙØ± Ø­ØªÙ‰ Ø§Ù„Ø§Ø­ØªØ±Ø§Ù.<br/>
<a href="https://www.youtube.com/playlist?list=PLp2eAGIFKMEVnAAJWhGzLc1Nn-tFP1UHP">Ù…Ø´Ø§Ù‡Ø¯Ø© Ø§Ù„ÙƒÙˆØ±Ø³</a></p></li>
<li><p><strong>Mastering Django in 2023 (Arabic)</strong>: Ø³Ù„Ø³Ù„Ø© ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ù…ØªÙ‚Ø¯Ù…Ø© Ù„ØªØ¹Ù„Ù… Django.<br/>
<a href="https://www.youtube.com/watch?v=rJVQ7X77fxw">Ù…Ø´Ø§Ù‡Ø¯Ø© Ø§Ù„Ø³Ù„Ø³Ù„Ø©</a></p></li>
</ul>
<h3>ğŸ”µ Deep Learning:</h3>
<ul>
<li><p><strong>Ø¯ÙˆØ±Ø© Ø§Ù„ØªØ­Ø¶ÙŠØ± Ù„Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</strong>: Ø¯ÙˆØ±Ø© Ø´Ø§Ù…Ù„Ø© Ù„ØªØ¹Ù„Ù… Python ÙˆØ§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ù…Ù† Ø§Ù„ØµÙØ±.<br/>
<a href="https://www.udemy.com/course/machine-learning-and-deep-learning-for-arabs/">Ù…Ø´Ø§Ù‡Ø¯Ø© Ø§Ù„Ø¯ÙˆØ±Ø©</a></p></li>
<li><p><strong>Deep Learning MiniCamp [Arabic]</strong>: Ø¯ÙˆØ±Ø© Ù…ØªÙ‚Ø¯Ù…Ø© ÙÙŠ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Keras ÙˆTensorFlow.<br/>
<a href="https://www.udemy.com/course/intro-to-deep-learning-arabic/">Ù…Ø´Ø§Ù‡Ø¯Ø© Ø§Ù„Ø¯ÙˆØ±Ø©</a></p></li>
<li><p><strong>Ù…Ù‚Ø¯Ù…Ø© Ø¹Ù† Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø§ØªÙ„Ø§Ø¨</strong>: Ø³Ù„Ø³Ù„Ø© ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ø­ÙˆÙ„ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… MATLAB.<br/>
<a href="https://www.youtube.com/playlist?list=PLAI6JViu7XmflH_eGgsWkwvv6lbXhYjjY">Ù…Ø´Ø§Ù‡Ø¯Ø© Ø§Ù„Ø³Ù„Ø³Ù„Ø©</a></p></li>
</ul>
</body>
</html>
